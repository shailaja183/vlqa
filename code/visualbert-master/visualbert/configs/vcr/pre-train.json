{
  "dataset": "vcr",

  "rationale": false,

  "vcr_annots_dir":"X_VCR", //Please replace this with the actual corresponding folder
  "vcr_image_dir":"X_VCR/vcr1images", //Please replace this with the actual corresponding folder

  "use_fixed_feature": false,
  "image_screening_parameters": null,

  "use_alignment": true,
  "special_screen": false,
  "add_all_features": true,

  "fp16": false,
  "loss_scale": 256, 

  "max_seq_length": 128,
  "bert_model_name": "bert-base-uncased",
  "do_lower_case": true,
  "train_batch_size": 32,
  "eval_batch_size":  32,

  "pretraining": true,
  "pretraining_include_qa_and_qar": true, // Whether we want to include qar for pre-training
  "complete_shuffle": true,

  // Optimizer stuff
  "patience": 3,
  "learning_rate": 5e-5,
  "num_train_epochs":  1,
  "warmup_proportion": 0.1879, // Chosen to match R2C's task-specific pre-training
  "grad_norm": 1.0,
  "gradient_accumulation_steps": 1,

  "restore_bin": null,  //Specify which model to initialize from

  "num_workers": 4,
  "val_workers": 2,

  "model": // Used for AllenNLP registed BERT model
  {
    "type": "VisualBERTDetector",
    "special_visual_initialize": true,
    "training_head_type": "pretraining",
    "visual_embedding_dim": 512
  }
}
